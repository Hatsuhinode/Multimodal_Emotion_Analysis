{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "274c3f94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:38:37.816142Z",
     "iopub.status.busy": "2025-02-05T17:38:37.815744Z",
     "iopub.status.idle": "2025-02-05T17:38:37.821581Z",
     "shell.execute_reply": "2025-02-05T17:38:37.820775Z"
    },
    "papermill": {
     "duration": 0.013993,
     "end_time": "2025-02-05T17:38:37.823367",
     "exception": false,
     "start_time": "2025-02-05T17:38:37.809374",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note:\n",
    "\n",
    "# The following files are the outputs of the Kaggle notebook titled \"MELD: Removing Corrupted Records\".\n",
    "# They provide cleaned datasets by excluding corrupted records and include information about the removed entries.\n",
    "\n",
    "\n",
    "\n",
    "# Corrupted Files Information:\n",
    "\n",
    "# Corrupted videos: \n",
    "\n",
    "# {'train': [{'125_3': '/kaggle/input/meld-emotion-recognition/MELD.Raw/MELD.Raw/train/train_splits/dia125_utt3.mp4', 'y': 0, 'label': 'neutral'}], \n",
    "#  'dev': [{'110_7': '/kaggle/input/meld-emotion-recognition/MELD.Raw/MELD.Raw/dev/dev_splits_complete/dia110_utt7.mp4', 'y': 0, 'label': 'neutral'}], \n",
    "#  'test': []}\n",
    "\n",
    "\n",
    "\n",
    "# Corrupted audios: \n",
    "\n",
    "# {'train': [{'125_3': '/kaggle/input/meld-audio/audio_train/dia125_utt3.wav', 'y': 0, 'label': 'neutral'}], \n",
    "#  'dev': [{'110_7': '/kaggle/input/meld-audio/audio_dev/dia110_utt7.wav', 'y': 0, 'label': 'neutral'}], \n",
    "#  'test': []}\n",
    "\n",
    "\n",
    "\n",
    "# File Details:\n",
    "\n",
    "# 1. \"/kaggle/input/meld-emotion-recognition/JSON files/JSON files/Updated CSV/dev_sent_emo_cleaned.csv\"\n",
    "\n",
    "#    This file contains the cleaned version of dev_sent_emo.csv. Rows corresponding to corrupted video or audio\n",
    "#    files were removed. Specifically, records with Dialogue_ID and Utterance_ID forming the key \"110_7\" were\n",
    "#    excluded based on the corrupted file information in:\n",
    "#    - Corrupted videos: /kaggle/input/meld-emotion-recognition/JSON files/JSON files/MELD Data Format/MELD_corrupted_video_data.json\n",
    "#    - Corrupted audios: /kaggle/input/meld-emotion-recognition/JSON files/JSON files/MELD Data Format/MELD_corrupted_audio_data.json\n",
    "\n",
    "\n",
    "\n",
    "# 2. \"/kaggle/input/meld-emotion-recognition/JSON files/JSON files/Updated CSV/train_sent_emo_cleaned.csv\"\n",
    "\n",
    "#    This file contains the cleaned version of train_sent_emo.csv. Rows with Dialogue_ID and Utterance_ID\n",
    "#    forming the key \"125_3\" were removed based on corrupted file data from the same sources as above.\n",
    "\n",
    "\n",
    "\n",
    "# 3. \"/kaggle/input/meld-emotion-recognition/JSON files/JSON files/Updated CSV/test_sent_emo_cleaned.csv\"\n",
    "\n",
    "#    This file is identical to test_sent_emo.csv, as no corrupted files (video or audio) were found in the \"test\"\n",
    "#    split. Consequently, no records were removed.\n",
    "\n",
    "\n",
    "\n",
    "# 4. \"/kaggle/input/meld-emotion-recognition/JSON files/JSON files/Updated CSV/dev_sent_emo_removed.csv\"\n",
    "\n",
    "#    This file lists the records removed from dev_sent_emo.csv. The removed records correspond to Dialogue_ID and\n",
    "#    Utterance_ID values of \"110\" and \"7\", respectively.\n",
    "\n",
    "\n",
    "\n",
    "# 5. \"/kaggle/input/meld-emotion-recognition/JSON files/JSON files/Updated CSV/train_sent_emo_removed.csv\"\n",
    "\n",
    "#    This file contains the records removed from train_sent_emo.csv. The excluded records correspond to Dialogue_ID\n",
    "#    and Utterance_ID values of \"125\" and \"3\", respectively.\n",
    "\n",
    "\n",
    "\n",
    "# 6. \"/kaggle/input/meld-emotion-recognition/JSON files/JSON files/Updated CSV/test_sent_emo_removed.csv\"\n",
    "\n",
    "#    This file is empty, as no corrupted video or audio files were present in the \"test\" split. Thus, no records\n",
    "#    were removed from test_sent_emo.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02fd8291",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:38:37.833393Z",
     "iopub.status.busy": "2025-02-05T17:38:37.833045Z",
     "iopub.status.idle": "2025-02-05T17:38:37.836780Z",
     "shell.execute_reply": "2025-02-05T17:38:37.835866Z"
    },
    "papermill": {
     "duration": 0.010559,
     "end_time": "2025-02-05T17:38:37.838499",
     "exception": false,
     "start_time": "2025-02-05T17:38:37.827940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THE KAGGLE NOTEBOOK `MELD : Updated MELD Data JSON Files` IS USED TO UPDATE THE JSON FORMAT FILES FOR MELD DATASET \n",
    "# SO THAT THE ENTRIES CORRESPONDING TO THE RECORDS IN MELD_corrupted_video_data.json OR MELD_corrupted_audio_data.json, \n",
    "# WHICH REPRESENT THE CORRUPTED VIDEO OR AUDIO FILES IN THE MELD DATASET, ARE REMOVED.\n",
    "\n",
    "# JSON FORMAT FILES FOR MELD DATASET THAT IS TO BE UPDATED:\n",
    "\n",
    "# 1. MELD_Data.json\n",
    "# 2. MELD_Textual_Data.json\n",
    "# 3. MELD_Video_Data.json\n",
    "# 4. MELD_audio_data_updated.json\n",
    "\n",
    "# THE JSON FILES USED FOR UPDATING THE ABOVE FILES:\n",
    "\n",
    "# 1. MELD_corrupted_video_data.json\n",
    "# 2. MELD_corrupted_audio_data.json\n",
    "\n",
    "# THE OUTPUT OBTAINED AFTER REMOVING CORRUPTED ENTRIES:\n",
    "\n",
    "# 1. MELD_Data_Cleaned.json\n",
    "# 2. MELD_Textual_Data_Cleaned.json\n",
    "# 3. MELD_Video_Data_Cleaned.json\n",
    "# 4. MELD_Audio_Data_Updated_Cleaned.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4673c70",
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2025-02-05T17:38:37.848522Z",
     "iopub.status.busy": "2025-02-05T17:38:37.848187Z",
     "iopub.status.idle": "2025-02-05T17:38:37.852212Z",
     "shell.execute_reply": "2025-02-05T17:38:37.851315Z"
    },
    "jupyter": {
     "outputs_hidden": true
    },
    "papermill": {
     "duration": 0.01077,
     "end_time": "2025-02-05T17:38:37.853779",
     "exception": false,
     "start_time": "2025-02-05T17:38:37.843009",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# THE OUTPUT OF THE KAGGLE NOTEBOOK \"MELD: Removing Corrupted Records\" ARE:\n",
    "\n",
    "# 1. train_sent_emo_cleaned.csv\n",
    "# 2. dev_sent_emo_cleaned.csv\n",
    "# 3. test_sent_emo_cleaned.csv\n",
    "\n",
    "# 4. train_sent_emo_removed.csv\n",
    "# 5. dev_sent_emo_removed.csv\n",
    "# 6. test_sent_emo_removed.csv\n",
    "\n",
    "# 7. MELD_corrupted_video_data.json\n",
    "# 8. MELD_corrupted_audio_data.json\n",
    "\n",
    "\n",
    "\n",
    "# AMONG THE CSV FILES \"train_sent_emo_cleaned.csv\", \"dev_sent_emo_cleaned.csv\" and \"test_sent_emo_cleaned.csv\",\n",
    "# THERE IS A COLUMN NAMED \"Utterance\" WHICH CONTAINS CONVERSATIONS.\n",
    "# THESE CONVERSATIONS (IN TEXTUAL FORM) INCLUDE SPECIAL CHARACTERS SUCH AS \\x92\n",
    "# (FOR EXAMPLE, INSTEAD OF \"he's\", IT CONTAINS \"he\\x92s\").\n",
    "# THEREFORE, WE NEED TO PROCESS THESE CSV FILES.\n",
    "\n",
    "\n",
    "\n",
    "# THUS, THE KAGGLE NOTEBOOK \"Detecting Special Characters in Text Data\" PROCESSES THESE CSV FILES\n",
    "# AND REPLACES SUCH SPECIAL CHARACTERS.\n",
    "# THE OUTPUT OBTAINED AFTER RUNNING THIS NOTEBOOK ARE:\n",
    "\n",
    "# 1. train_sent_emo_cleaned_processed.csv\n",
    "# 2. dev_sent_emo_cleaned_processed.csv\n",
    "# 3. test_sent_emo_cleaned_processed.csv\n",
    "\n",
    "\n",
    "\n",
    "# NOW, WE NEED TO STRUCTURE THESE CSV FILES INTO JSON FORMAT.\n",
    "\n",
    "\n",
    "\n",
    "# SO, WE USE THE CODE IN THE KAGGLE NOTEBOOK \"MELD : Structuring Text and Video Data\" WITHIN THIS NOTEBOOK \"MELD : Structuring MELD Data and Text Data\"\n",
    "# TO STRUCTURE THE MELD DATA AND TEXT DATA IN JSON FORMAT.\n",
    "\n",
    "\n",
    "# THE OUTPUT OF THIS KAGGLE NOTEBOOK ARE:\n",
    "\n",
    "# 1. MELD_Data_Cleaned_Processed.json\n",
    "# 2. MELD_Textual_Data_Cleaned_Processed.json\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# FINALLY, WE CAN USE THE FOLLOWING FILES FOR BUILDING OUR MACHINE LEARNING MODEL:\n",
    "\n",
    "# 1. MELD_Data_Cleaned_Processed.json\n",
    "# 2. MELD_Textual_Data_Cleaned_Processed.json\n",
    "# 3. MELD_Video_Data_Cleaned.json\n",
    "# 4. MELD_Audio_Data_Cleaned.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82240d45",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.003964,
     "end_time": "2025-02-05T17:38:37.862308",
     "exception": false,
     "start_time": "2025-02-05T17:38:37.858344",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Analyzing .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab2eadb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:38:37.872179Z",
     "iopub.status.busy": "2025-02-05T17:38:37.871790Z",
     "iopub.status.idle": "2025-02-05T17:38:38.803560Z",
     "shell.execute_reply": "2025-02-05T17:38:38.802554Z"
    },
    "papermill": {
     "duration": 0.938777,
     "end_time": "2025-02-05T17:38:38.805457",
     "exception": false,
     "start_time": "2025-02-05T17:38:37.866680",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4faa22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:38:38.815397Z",
     "iopub.status.busy": "2025-02-05T17:38:38.814853Z",
     "iopub.status.idle": "2025-02-05T17:38:38.917736Z",
     "shell.execute_reply": "2025-02-05T17:38:38.916896Z"
    },
    "papermill": {
     "duration": 0.109666,
     "end_time": "2025-02-05T17:38:38.919557",
     "exception": false,
     "start_time": "2025-02-05T17:38:38.809891",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sent_emo = pd.read_csv('/kaggle/input/meld-emotion-recognition/JSON files/JSON files/CSV Processed/train_sent_emo_cleaned_processed.csv')\n",
    "dev_sent_emo = pd.read_csv('/kaggle/input/meld-emotion-recognition/JSON files/JSON files/CSV Processed/dev_sent_emo_cleaned_processed.csv')\n",
    "test_sent_emo = pd.read_csv('/kaggle/input/meld-emotion-recognition/JSON files/JSON files/CSV Processed/test_sent_emo_cleaned_processed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ce8db0",
   "metadata": {
    "papermill": {
     "duration": 0.00394,
     "end_time": "2025-02-05T17:38:38.928090",
     "exception": false,
     "start_time": "2025-02-05T17:38:38.924150",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293edf9a",
   "metadata": {
    "papermill": {
     "duration": 0.003893,
     "end_time": "2025-02-05T17:38:38.936126",
     "exception": false,
     "start_time": "2025-02-05T17:38:38.932233",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Functions to Save and Read Data in JSON Format Using Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4406d27",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:38:38.945488Z",
     "iopub.status.busy": "2025-02-05T17:38:38.945150Z",
     "iopub.status.idle": "2025-02-05T17:38:38.949021Z",
     "shell.execute_reply": "2025-02-05T17:38:38.948196Z"
    },
    "papermill": {
     "duration": 0.010263,
     "end_time": "2025-02-05T17:38:38.950490",
     "exception": false,
     "start_time": "2025-02-05T17:38:38.940227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59b9f18f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:38:38.960152Z",
     "iopub.status.busy": "2025-02-05T17:38:38.959786Z",
     "iopub.status.idle": "2025-02-05T17:38:38.964817Z",
     "shell.execute_reply": "2025-02-05T17:38:38.964031Z"
    },
    "papermill": {
     "duration": 0.011618,
     "end_time": "2025-02-05T17:38:38.966381",
     "exception": false,
     "start_time": "2025-02-05T17:38:38.954763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_to_json(data, file_path):\n",
    "    \"\"\"\n",
    "    Save data to a JSON file.\n",
    "    \n",
    "    Args:\n",
    "    - data: Python object (e.g., dict or list) to save.\n",
    "    - file_path: Path to the JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"w\") as json_file:\n",
    "            json.dump(data, json_file, indent=4)  # Save with pretty formatting\n",
    "        print(f\"Data successfully saved to {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving data to JSON: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1c1253e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:38:38.976235Z",
     "iopub.status.busy": "2025-02-05T17:38:38.975830Z",
     "iopub.status.idle": "2025-02-05T17:38:38.980417Z",
     "shell.execute_reply": "2025-02-05T17:38:38.979538Z"
    },
    "papermill": {
     "duration": 0.011003,
     "end_time": "2025-02-05T17:38:38.981862",
     "exception": false,
     "start_time": "2025-02-05T17:38:38.970859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def read_from_json(file_path):\n",
    "    \"\"\"\n",
    "    Read data from a JSON file.\n",
    "    \n",
    "    Args:\n",
    "    - file_path: Path to the JSON file.\n",
    "    \n",
    "    Returns:\n",
    "    - The Python object (e.g., dict or list) loaded from the JSON file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            data = json.load(json_file)\n",
    "        print(f\"Data successfully loaded from {file_path}\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading data from JSON: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caec682",
   "metadata": {
    "papermill": {
     "duration": 0.004143,
     "end_time": "2025-02-05T17:38:38.990608",
     "exception": false,
     "start_time": "2025-02-05T17:38:38.986465",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22340ec4",
   "metadata": {
    "papermill": {
     "duration": 0.003972,
     "end_time": "2025-02-05T17:38:38.999079",
     "exception": false,
     "start_time": "2025-02-05T17:38:38.995107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Structuring MELD Data for Emotion Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12f189f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:38:39.008841Z",
     "iopub.status.busy": "2025-02-05T17:38:39.008528Z",
     "iopub.status.idle": "2025-02-05T17:41:12.783159Z",
     "shell.execute_reply": "2025-02-05T17:41:12.782105Z"
    },
    "papermill": {
     "duration": 153.781914,
     "end_time": "2025-02-05T17:41:12.785226",
     "exception": false,
     "start_time": "2025-02-05T17:38:39.003312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the CSV files\n",
    "train_df = pd.read_csv('/kaggle/input/meld-emotion-recognition/JSON files/JSON files/CSV Processed/train_sent_emo_cleaned_processed.csv')\n",
    "dev_df = pd.read_csv('/kaggle/input/meld-emotion-recognition/JSON files/JSON files/CSV Processed/dev_sent_emo_cleaned_processed.csv')\n",
    "test_df = pd.read_csv('/kaggle/input/meld-emotion-recognition/JSON files/JSON files/CSV Processed/test_sent_emo_cleaned_processed.csv')\n",
    "\n",
    "# Concatenate all data into a single DataFrame\n",
    "df = pd.concat([train_df, dev_df, test_df])\n",
    "\n",
    "# Define the label index for emotions\n",
    "label_index = {\n",
    "    \"neutral\": 0,\n",
    "    \"surprise\": 1,\n",
    "    \"fear\": 2,\n",
    "    \"sadness\": 3,\n",
    "    \"joy\": 4,\n",
    "    \"disgust\": 5,\n",
    "    \"anger\": 6\n",
    "}\n",
    "\n",
    "# Initialize the data structure\n",
    "MELD_data = {\n",
    "    \"data\": [],\n",
    "    \"max_sentence_length\": 30,\n",
    "    \"label_index\": label_index\n",
    "}\n",
    "\n",
    "# Helper function to find the split by comparing rows\n",
    "def get_split(row):\n",
    "    # Drop 'Sr No.' from the DataFrame and compare the rest of the columns\n",
    "    row_without_srno = row.drop('Sr No.')\n",
    "    \n",
    "    # Check if the row exists in the train_df (excluding 'Sr No.')\n",
    "    if (train_df.drop('Sr No.', axis=1) == row_without_srno).all(axis=1).any():\n",
    "        return \"train\"\n",
    "    \n",
    "    # Check if the row exists in the dev_df (excluding 'Sr No.')\n",
    "    elif (dev_df.drop('Sr No.', axis=1) == row_without_srno).all(axis=1).any():\n",
    "        return \"dev\"\n",
    "    \n",
    "    # Check if the row exists in the test_df (excluding 'Sr No.')\n",
    "    elif (test_df.drop('Sr No.', axis=1) == row_without_srno).all(axis=1).any():\n",
    "        return \"test\"\n",
    "    \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Process each row in the DataFrame and append to the data format\n",
    "for index, row in df.iterrows():\n",
    "    # Get the split using the helper function\n",
    "    split = get_split(row)\n",
    "\n",
    "    if split is None:\n",
    "        print(f\"Row mismatch: {row['Season']}, {row['Episode']}, {row['Dialogue_ID']}, {row['Utterance_ID']}\")\n",
    "        continue  # Skip rows that don't match any split\n",
    "    \n",
    "    entry = {\n",
    "        \"text\": row[\"Utterance\"],\n",
    "        \"split\": split,\n",
    "        \"y\": label_index.get(row[\"Emotion\"].lower(), -1),  # Get emotion label\n",
    "        \"dialog\": row[\"Dialogue_ID\"],\n",
    "        \"utterance\": row[\"Utterance_ID\"],\n",
    "        \"season\": row[\"Season\"],\n",
    "        \"episode\": row[\"Episode\"],\n",
    "        \"num_words\": len(row[\"Utterance\"].split()),\n",
    "        \"dia_utt\": f\"{row['Dialogue_ID']}_{row['Utterance_ID']}\",\n",
    "        \"speaker\": row[\"Speaker\"]\n",
    "    }\n",
    "    \n",
    "    # Append the entry to the data\n",
    "    MELD_data[\"data\"].append(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c16e9f9",
   "metadata": {
    "papermill": {
     "duration": 0.004127,
     "end_time": "2025-02-05T17:41:12.794348",
     "exception": false,
     "start_time": "2025-02-05T17:41:12.790221",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c1dd1f",
   "metadata": {
    "papermill": {
     "duration": 0.004034,
     "end_time": "2025-02-05T17:41:12.802808",
     "exception": false,
     "start_time": "2025-02-05T17:41:12.798774",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save MELD Data in JSON Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1c2b35f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:41:12.812857Z",
     "iopub.status.busy": "2025-02-05T17:41:12.812504Z",
     "iopub.status.idle": "2025-02-05T17:41:13.043100Z",
     "shell.execute_reply": "2025-02-05T17:41:13.041784Z"
    },
    "papermill": {
     "duration": 0.237945,
     "end_time": "2025-02-05T17:41:13.045119",
     "exception": false,
     "start_time": "2025-02-05T17:41:12.807174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to /kaggle/working/MELD_Data_Cleaned_Processed.json\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Filepath\n",
    "    MELD_data_file_path = \"/kaggle/working/MELD_Data_Cleaned_Processed.json\"\n",
    "\n",
    "    # Save data to JSON\n",
    "    save_to_json(MELD_data, MELD_data_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e0ecb6",
   "metadata": {
    "papermill": {
     "duration": 0.00427,
     "end_time": "2025-02-05T17:41:13.054286",
     "exception": false,
     "start_time": "2025-02-05T17:41:13.050016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41b973e",
   "metadata": {
    "papermill": {
     "duration": 0.004202,
     "end_time": "2025-02-05T17:41:13.062820",
     "exception": false,
     "start_time": "2025-02-05T17:41:13.058618",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Structuring Text Data for Emotion Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe43f229",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:41:13.072803Z",
     "iopub.status.busy": "2025-02-05T17:41:13.072453Z",
     "iopub.status.idle": "2025-02-05T17:41:13.100741Z",
     "shell.execute_reply": "2025-02-05T17:41:13.099790Z"
    },
    "papermill": {
     "duration": 0.035288,
     "end_time": "2025-02-05T17:41:13.102465",
     "exception": false,
     "start_time": "2025-02-05T17:41:13.067177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Initialize the text_data dictionary\n",
    "MELD_textual_data = {\n",
    "    \"train\": [],\n",
    "    \"dev\": [],\n",
    "    \"test\": []\n",
    "}\n",
    "\n",
    "\n",
    "# Loop through the data_format and organize text accordingly\n",
    "for split in ['train', 'dev', 'test']:\n",
    "    for entry in MELD_data[\"data\"]:\n",
    "        if entry[\"split\"] == split:  # Check if the split matches\n",
    "            # Construct the key for text (e.g., \"0_0\")\n",
    "            text_key = entry[\"dia_utt\"]\n",
    "            \n",
    "            \n",
    "            # Extract the emotion label and index from data_format\n",
    "            emotion_label = list(MELD_data[\"label_index\"].keys())[entry[\"y\"]]\n",
    "            # Create the dictionary for the text entry\n",
    "            text_entry = {\n",
    "                text_key: entry[\"text\"],\n",
    "                \"y\": entry[\"y\"],\n",
    "                \"label\": emotion_label\n",
    "            }\n",
    "            \n",
    "            # Add the text entry to the appropriate split in text_data\n",
    "            MELD_textual_data[split].append(text_entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248206f2",
   "metadata": {
    "papermill": {
     "duration": 0.004277,
     "end_time": "2025-02-05T17:41:13.111419",
     "exception": false,
     "start_time": "2025-02-05T17:41:13.107142",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ac656f",
   "metadata": {
    "papermill": {
     "duration": 0.004139,
     "end_time": "2025-02-05T17:41:13.120380",
     "exception": false,
     "start_time": "2025-02-05T17:41:13.116241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Save MELD Textual Data in JSON Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bddcfcd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-05T17:41:13.130529Z",
     "iopub.status.busy": "2025-02-05T17:41:13.130207Z",
     "iopub.status.idle": "2025-02-05T17:41:13.229304Z",
     "shell.execute_reply": "2025-02-05T17:41:13.227965Z"
    },
    "papermill": {
     "duration": 0.10636,
     "end_time": "2025-02-05T17:41:13.231174",
     "exception": false,
     "start_time": "2025-02-05T17:41:13.124814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to /kaggle/working/MELD_Textual_Data_Cleaned_Processed.json\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Filepath\n",
    "    MELD_textual_data_file_path = \"/kaggle/working/MELD_Textual_Data_Cleaned_Processed.json\"\n",
    "\n",
    "    # Save data to JSON\n",
    "    save_to_json(MELD_textual_data, MELD_textual_data_file_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 6525542,
     "sourceId": 10671594,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 158.766396,
   "end_time": "2025-02-05T17:41:13.856760",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-05T17:38:35.090364",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
